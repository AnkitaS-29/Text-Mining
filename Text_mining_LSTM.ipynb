{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=[]\n",
    "for doc in glob.glob('C:/Users/sirola/Desktop/Insofe/CUTe4/Data/*'):\n",
    "    with(open(doc, 'r')) as f:\n",
    "        text = f.readlines()\n",
    "        text = ''.join(text)\n",
    "        text=re.sub('<.*>','',text)\n",
    "        text=re.sub('\\'','',text)\n",
    "        text=re.sub('\\n|\\t',' ',text)\n",
    "        text=re.sub('[\\d]','',text)\n",
    "        text=re.sub('[$]','',text) \n",
    "        text=re.sub('[^(a-z|A-Z|\\s)]','',text)        \n",
    "    document.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "for labels in glob.glob('C:/Users/sirola/Desktop/Insofe/CUTe4/Data/*'):\n",
    "    tclass=re.split('_',labels)[1]\n",
    "    label.append(tclass)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In article  freddshuksan (Fred Dickey) write...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In article  gwmsplsplloralcom (Gary W Mahan)...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THANKS TO ALL OF YOU WHO RESPONDED TO MY POS...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The subject says it all My  Chev S Pickups l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNTPPostingHost blackercaltechedu    wolfsonre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document Target\n",
       "0    In article  freddshuksan (Fred Dickey) write...      2\n",
       "1    In article  gwmsplsplloralcom (Gary W Mahan)...      2\n",
       "2    THANKS TO ALL OF YOU WHO RESPONDED TO MY POS...      2\n",
       "3    The subject says it all My  Chev S Pickups l...      2\n",
       "4  NNTPPostingHost blackercaltechedu    wolfsonre...      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame([document,label]).T\n",
    "data.columns=['Document','Target']\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' '3' '4' '5' '6']\n",
      "[1000 1006  999  989  997  993]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Numpy library for creating and modifying arrays.\n",
    "\n",
    "\n",
    "# Print the unique classes and their counts/frequencies\n",
    "classes = np.unique(data['Target'], return_counts=True) # np.unique returns a tuple with class names and counts\n",
    "print(classes[0]) #Print the list of unique classes\n",
    "print(classes[1]) #Print the list of frequencies of the above classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>frankDSuucp (Frank ODwyer) writes   In artic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>MessageID   References   NNTPPostingHost dolph...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Distribution world  MessageID   References   R...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>In article rindenterprisebihharvardedu (Davi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>I just bought a little gizmo that is suppo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Document Target\n",
       "1947    frankDSuucp (Frank ODwyer) writes   In artic...      1\n",
       "2644  MessageID   References   NNTPPostingHost dolph...      3\n",
       "330   Distribution world  MessageID   References   R...      2\n",
       "3584    In article rindenterprisebihharvardedu (Davi...      4\n",
       "2530      I just bought a little gizmo that is suppo...      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=data.sample(frac=0.7)\n",
    "test=data.drop(train.index)\n",
    "\n",
    "train.shape\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words = 10000\n",
    "seq_len = 50\n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4189, 50), (1795, 50))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\n",
    "tokenizer.fit_on_texts(train.Document) #Fit this to our corpus\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(train.Document) #'text to sequences converts the text to a list of indices\n",
    "x_train = pad_sequences(x_train, maxlen=50) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "\n",
    "x_test = tokenizer.texts_to_sequences(test.Document) \n",
    "x_test = pad_sequences(x_test, maxlen=50)\n",
    "\n",
    "x_train.shape, x_test.shape # Check the dimensions of x_train and x_test .shape, x_test.shape # Check the dimensions of x_train and x_test  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '3', '2', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(train.Target.unique())\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical # This convers the labels to one-hot vectors(Dummies)\n",
    "\n",
    "y_train = np.array([unique_labels.index(i) for i in train.Target]) # Convert the word labels to indeces\n",
    "y_train = to_categorical(y_train) # Dummify the labels\n",
    "y_test = np.array([unique_labels.index(i) for i in test.Target])\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM, Embedding,Dropout # Import layers from Keras\n",
    "from keras.models import Sequential\n",
    "# Building an LSTM model\n",
    "model = Sequential() # Call Sequential to initialize a network\n",
    "model.add(Embedding(input_dim = max_num_words, \n",
    "                    input_length = seq_len, \n",
    "                    output_dim = embedding_size)) # Add an embedding layer which represents each unique token as a vector\n",
    "model.add(LSTM(10, return_sequences=True))# Add an LSTM layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(10, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, activation='softmax')) # Add an ouput layer. Since classification, 3 nodes for 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 10)            4440      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "=================================================================\n",
      "Total params: 1,005,346\n",
      "Trainable params: 1,005,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3141 samples, validate on 1048 samples\n",
      "Epoch 1/5\n",
      "3141/3141 [==============================] - 44s 14ms/step - loss: 1.7606 - acc: 0.2283 - val_loss: 1.6149 - val_acc: 0.2996\n",
      "Epoch 2/5\n",
      "3141/3141 [==============================] - 35s 11ms/step - loss: 1.5018 - acc: 0.3451 - val_loss: 1.4504 - val_acc: 0.4017\n",
      "Epoch 3/5\n",
      "3141/3141 [==============================] - 29s 9ms/step - loss: 1.2484 - acc: 0.4766 - val_loss: 1.3116 - val_acc: 0.5324\n",
      "Epoch 4/5\n",
      "3141/3141 [==============================] - 33s 10ms/step - loss: 1.0455 - acc: 0.6122 - val_loss: 1.2119 - val_acc: 0.6135\n",
      "Epoch 5/5\n",
      "3141/3141 [==============================] - 32s 10ms/step - loss: 0.8848 - acc: 0.6823 - val_loss: 1.1890 - val_acc: 0.6288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f1c075f60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mention the optimizer, Loss function and metrics to be computed\n",
    "model.compile(optimizer=adam,                  # 'Adam' is a variant of gradient descent technique\n",
    "              loss='categorical_crossentropy', # categorical_crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])            # These metrics are computed for evaluating and stored in history\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob = model.predict(x_test)\n",
    "test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00446592, 0.07487506, 0.52626747, 0.0189277 , 0.07338848,\n",
       "        0.30207533],\n",
       "       [0.00167764, 0.04531724, 0.47906646, 0.00192823, 0.0145673 ,\n",
       "        0.45744315],\n",
       "       [0.00267257, 0.05991123, 0.49982387, 0.00435177, 0.0245114 ,\n",
       "        0.40872914],\n",
       "       [0.07071646, 0.22765464, 0.22574715, 0.11254576, 0.16830523,\n",
       "        0.1950307 ],\n",
       "       [0.0016872 , 0.03129255, 0.55569595, 0.00316668, 0.02708302,\n",
       "        0.3810746 ],\n",
       "       [0.00943799, 0.03809113, 0.46868163, 0.01825872, 0.14203596,\n",
       "        0.32349455]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = model.predict_classes(x_test)\n",
    "test_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = np.argmax(test_prob, axis=1)\n",
    "test_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
